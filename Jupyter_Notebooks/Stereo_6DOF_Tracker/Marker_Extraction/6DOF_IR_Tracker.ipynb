{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclustering.cluster.bsas import bsas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "fig_size =[12,9]\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('faulty_image.jpg')\n",
    "img_gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret,img_thresh = cv2.threshold(img_gray,100,255,cv2.THRESH_TOZERO)\n",
    "nonzro_samples = cv2.findNonZero(img_thresh).reshape(-1, 2).astype('float32')\n",
    "plt.imshow(img_thresh,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clusters = 8\n",
    "threshold = 20\n",
    "bsas_instance = bsas(nonzro_samples, max_clusters, threshold)\n",
    "bsas_instance.process()\n",
    "clusters = bsas_instance.get_clusters()\n",
    "#representatives = bsas_instance.get_representatives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms=[]\n",
    "ROIs=np.zeros((len(clusters),4))\n",
    "for i,cluster in enumerate(clusters):\n",
    "    current_batch=nonzro_samples[cluster]\n",
    "    cms.append(np.sum(current_batch,axis=0)/current_batch.shape[0])\n",
    "    row_max=np.max(current_batch[:,1],axis=0)+6\n",
    "    row_min=np.min(current_batch[:,1],axis=0)-6\n",
    "    col_max=np.max(current_batch[:,0],axis=0)+6\n",
    "    col_min=np.min(current_batch[:,0],axis=0)-6\n",
    "    ROIs[i,:]=[row_min,row_max,col_min,col_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ROIs=[]\n",
    "for roi in ROIs.astype('int32'):\n",
    "    print(roi)\n",
    "    image_ROIs.append(img_thresh.copy()[roi[0]:roi[1],roi[2]:roi[3]])\n",
    "plt.imshow(image_ROIs[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0 #Which ROI do you want to consider?\n",
    "frame=image_ROIs[index]\n",
    "roi_range=ROIs[index].astype('float32')\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "params.minThreshold = 50;\n",
    "params.maxThreshold = 255;\n",
    "params.filterByArea = True\n",
    "params.minArea = 0\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.1\n",
    "params.filterByConvexity = True\n",
    "params.minConvexity = 0.1\n",
    "params.filterByInertia = True\n",
    "params.minInertiaRatio = 0.1\n",
    "params.blobColor = 255\n",
    " \n",
    "ver = (cv2.__version__).split('.')\n",
    "if int(ver[0]) < 3 :\n",
    "    detector = cv2.SimpleBlobDetector(params)\n",
    "else : \n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "keypoints = detector.detect(frame)\n",
    "print(keypoints[0].pt)\n",
    "print(roi_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_clr=cv2.cvtColor(frame,cv2.COLOR_GRAY2RGB)\n",
    "im_with_keypoints = cv2.drawKeypoints(frame_clr, keypoints, np.array([]), (255,0,0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.imshow(frame_clr)\n",
    "for key in keypoints:\n",
    "    plt.plot(key.pt[0],key.pt[1],'r*')\n",
    "plt.show()\n",
    "img = cv2.imread('faulty_image.jpg')\n",
    "# roi_range[2] corresponds to roi_x_min and keypoints[0].pt[0] corresponds to the x component of the keypoint\n",
    "for key in keypoints:\n",
    "    cv2.circle(img,(int(round(key.pt[0]+roi_range[2])), int(round(key.pt[1]+roi_range[0]))), 2, (255,0,255), -1)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pyclustering.cluster.bsas import bsas\n",
    "class markerExteractor(object):\n",
    "    def __init__(self):\n",
    "        self.max_clusters = 8\n",
    "        self.threshold = 20\n",
    "        self.blubParams = cv2.SimpleBlobDetector_Params()\n",
    "        self.blubParams.minThreshold = 50;\n",
    "        self.blubParams.maxThreshold = 255;\n",
    "        self.blubParams.filterByArea = True\n",
    "        self.blubParams.minArea = 0\n",
    "        self.blubParams.filterByCircularity = True\n",
    "        self.blubParams.minCircularity = 0.3\n",
    "        self.blubParams.filterByConvexity = True\n",
    "        self.blubParams.minConvexity = 0.7\n",
    "        self.blubParams.filterByInertia = True\n",
    "        self.blubParams.minInertiaRatio = 0.1\n",
    "        self.blubParams.blobColor = 255\n",
    "        ver = (cv2.__version__).split('.')\n",
    "        if int(ver[0]) < 3 :\n",
    "            self.blubDetector = cv2.SimpleBlobDetector(self.blubParams)\n",
    "        else : \n",
    "            self.blubDetector = cv2.SimpleBlobDetector_create(self.blubParams)\n",
    "    def detect(self,frame):\n",
    "        self.cms=[]\n",
    "        self.image_ROIs=[]\n",
    "        self.keypoints=[]\n",
    "        img_gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret,img_thresh = cv2.threshold(img_gray,100,255,cv2.THRESH_TOZERO)\n",
    "        #Find the clusters\n",
    "        self.nonzro_samples = cv2.findNonZero(img_thresh)\n",
    "        if self.nonzro_samples is None:\n",
    "            return None\n",
    "        else:\n",
    "            self.nonzro_samples=self.nonzro_samples.reshape(-1, 2).astype('float32')\n",
    "        bsas_instance = bsas(self.nonzro_samples, self.max_clusters, self.threshold)\n",
    "        bsas_instance.process()\n",
    "        clusters = bsas_instance.get_clusters()\n",
    "        #Calculate the center of the clusters and the Regions of Interests\n",
    "        self.ROIs=np.zeros((len(clusters),4))\n",
    "        for i,cluster in enumerate(clusters):\n",
    "            current_batch=self.nonzro_samples[cluster]\n",
    "            self.cms.append(np.sum(current_batch,axis=0)/current_batch.shape[0])\n",
    "            row_max=np.max(current_batch[:,1],axis=0)+6\n",
    "            row_min=np.min(current_batch[:,1],axis=0)-6\n",
    "            col_max=np.max(current_batch[:,0],axis=0)+6\n",
    "            col_min=np.min(current_batch[:,0],axis=0)-6\n",
    "            self.ROIs[i,:]=[row_min,row_max,col_min,col_max]\n",
    "        for roi in self.ROIs.astype('int32'):\n",
    "            self.image_ROIs.append(img_thresh.copy()[roi[0]:roi[1],roi[2]:roi[3]])\n",
    "        #Return The Results\n",
    "        marker_points=[]\n",
    "        for i,roi in enumerate(self.image_ROIs):\n",
    "            keys_in_roi=self.blubDetector.detect(roi)\n",
    "            for key in keys_in_roi:\n",
    "                #Calculate the global coordinate of marker points. The points are returned in (X(Col),Y(Row)) coordinate. \n",
    "                marker_points.append([key.pt[0]+self.ROIs.astype('float32')[i,2],key.pt[1]+self.ROIs.astype('float32')[i,0]])\n",
    "        return np.array(marker_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('faulty_image.jpg')\n",
    "markerExteractor_inst=markerExteractor()\n",
    "points=markerExteractor_inst.detect(img)\n",
    "for i in range(len(points)):\n",
    "    cv2.circle(img,(int(round(points[i,0])), int(round(points[i,1]))), 2, (255,0,255), -1)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "cv2.imwrite('res.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the algorithm with a stream of images\n",
    "markerExteractor_inst=markerExteractor()\n",
    "cap=cv2.VideoCapture('/home/rouholla/Stereo_6DOF_Tracker/output_rigt.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output_debug.avi', fourcc, 30.0, (int(cap.get(3)),int(cap.get(4))))\n",
    "while cap.isOpened():\n",
    "    ret,img=cap.read()\n",
    "    raw_img=img.copy()\n",
    "    if ret==True:\n",
    "        points=markerExteractor_inst.detect(img)\n",
    "        if points is not None:\n",
    "            for i in range(len(points)):\n",
    "                cv2.circle(img,(int(round(points[i,0])), int(round(points[i,1]))), 2, (255,0,255), -1)\n",
    "        cv2.imshow('Frame',img)\n",
    "        out.write(img)\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            cv2.imwrite('faulty_image.jpg',raw_img)\n",
    "            break\n",
    "    else:\n",
    "        break #Break the while loop if no frames could be captured\n",
    "cv2.destroyAllWindows()     \n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "class undistrodMarkers:\n",
    "    def __init__(self,config_file_name):\n",
    "        with open(config_file_name, 'r') as f:\n",
    "            calib = yaml.safe_load(f.read())\n",
    "        self.K = np.array(calib['camera_matrix']['data']).reshape(calib['camera_matrix']['rows'],calib['camera_matrix']['cols'])\n",
    "        self.D = np.array(calib['distortion_coefficients']['data']).reshape(-1, 5)\n",
    "        self.P = np.array(calib['projection_matrix']['data']).reshape(3, 4)\n",
    "        self.R = np.array(calib['rectification_matrix']['data']).reshape(3, 3)\n",
    "        self.img_width = calib['image_width']\n",
    "        self.img_height = calib['image_height']\n",
    "    def process(self,points):\n",
    "        lpts_ud=cv2.undistortPoints(points.reshape(-1,1,2).astype(np.float32), self.K, self.D,P=self.P,R=self.R)\n",
    "        return cv2.convertPointsToHomogeneous(np.float32(lpts_ud))\n",
    "\n",
    "leftUndist = undistrodMarkers('/home/rouholla/Stereo_6DOF_Tracker/left.yaml')\n",
    "rightUndist = undistrodMarkers('/home/rouholla/Stereo_6DOF_Tracker/right.yaml')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2\n",
    "Now we use the tracker we just created to build our 6DOF tracker system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing the algorithm with a stream of images\n",
    "markerExteractor_inst=markerExteractor()\n",
    "cap_right=cv2.VideoCapture('/home/rouholla/Stereo_6DOF_Tracker/ouput_right.avi')\n",
    "cap_left=cv2.VideoCapture('/home/rouholla/Stereo_6DOF_Tracker/output_right.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output_debug.avi', fourcc, 30.0, (int(cap_left.get(3)),int(cap_left.get(4))))\n",
    "\n",
    "while cap_left.isOpened():\n",
    "    ret,img_left=cap_left.read()\n",
    "    ret,img_right=cap_right.read()\n",
    "    if ret==True:\n",
    "        points_left=markerExteractor_inst.detect(img_left)\n",
    "        points_right=markerExteractor_inst.detect(img_right)\n",
    "        if (points_left is not None) and (points_right is not None):\n",
    "            left_ud=leftUndist.process(points_left)\n",
    "            right_ud=rightUndist.process(points_right)\n",
    "            for i in range(min(len(points_left),len(points_right))):\n",
    "                cv2.circle(img_left,(int(round(points_left[i,0])), int(round(points_left[i,1]))), 2, (255,0,255), -1)\n",
    "                cv2.circle(img_right,(int(round(points_right[i,0])), int(round(points_right[i,1]))), 2, (255,0,255), -1)\n",
    "\n",
    "                \n",
    "        cv2.imshow('Frame',np.hstack([img_left,img_right]))\n",
    "        out.write(img_left)\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            cv2.imwrite('faulty_image.jpg',img_right)\n",
    "            break\n",
    "    else:\n",
    "        break #Break the while loop if no frames could be captured\n",
    "cv2.destroyAllWindows()     \n",
    "out.release()\n",
    "cap_left.release()\n",
    "cap_right.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lpts=np.array([329.875, 378.875]).reshape(1,2)\n",
    "#rpts=np.array([336.5, 334.5]).reshape(1,2)\n",
    "#left_ud=leftUndist.process(lpts)\n",
    "#right_ud=rightUndist.process(rpts)\n",
    "print(left_ud.reshape(-1,3))\n",
    "print ('right')\n",
    "print(right_ud.reshape(-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_ud-right_ud\n",
    "left_ud.reshape(-1,3)[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create the corresponding matrix\n",
    "def calculate_connection_mateix(left_points,right_points):\n",
    "    M=len(left_points)\n",
    "    N=len(right_points)\n",
    "    connection_matrix=np.zeros((M,N))\n",
    "    for i in range(0,M):\n",
    "        for j in range(0,N):\n",
    "                if(np.abs(left_points[i,1]-right_points[j,1])<10):\n",
    "                       connection_matrix[i,j]=1\n",
    "    return  connection_matrix\n",
    "\n",
    "def get_secondary_correspondings(matchesA,matchesB,points_left,points_right):\n",
    "    if len(matchesA)==0 or len(matchesB)==0:\n",
    "        return np.array([]),np.array([])\n",
    "    points_in_matchesA=[]\n",
    "    points_in_matchesB=[]\n",
    "    for clusters in matchesA:\n",
    "        points_in_cluster=points_left[clusters,:]\n",
    "        points_in_matchesA.append(points_in_cluster[points_in_cluster[:,0].argsort(),:])\n",
    "    for clusters in matchesB:\n",
    "        points_in_cluster=points_right[clusters,:]\n",
    "        points_in_matchesB.append(points_in_cluster[points_in_cluster[:,0].argsort(),:])\n",
    "\n",
    "    points_in_matchesA=np.vstack(points_in_matchesA)\n",
    "    points_in_matchesB=np.vstack(points_in_matchesB)\n",
    "    if points_in_matchesA.shape[0]==points_in_matchesB.shape[0]:\n",
    "        return points_in_matchesA,points_in_matchesB\n",
    "    else:\n",
    "        L=points_in_matchesA\n",
    "        R=points_in_matchesB\n",
    "        if(L.shape[0]<R.shape[0]):\n",
    "            dists=np.ma.array([(R-L[i,:])[:,1] for i in range(L.shape[0])],mask=False)\n",
    "            chosens=[]\n",
    "            for i in range(dists.shape[0]):\n",
    "                dists.mask[:,chosens]=True\n",
    "                chosens.append(np.argmin(dists[i,:]))\n",
    "            R=R[chosens,:]\n",
    "        else:\n",
    "\n",
    "            dists=np.ma.array([(L-R[i,:])[:,1] for i in range(R.shape[0])],mask=False).reshape(R.shape[0],-1)\n",
    "            chosens=[]\n",
    "            for i in range(dists.shape[0]):\n",
    "                dists.mask[:,chosens]=True\n",
    "                #print('a')\n",
    "                #print(dists)\n",
    "                chosens.append(np.argmin(dists[i,:]))\n",
    "            L=L[chosens,:]\n",
    "            \n",
    "        return L,R\n",
    "\n",
    "\n",
    "def process_filtered_connection_matrix(connection_matrix):\n",
    "    m,n=connection_matrix.shape\n",
    "    matchesA=[]\n",
    "    matchesB=[]\n",
    "    for i in range(m):\n",
    "        if connection_matrix[i,:].any()==1:\n",
    "            matche=np.where((connection_matrix==connection_matrix[i,:]).all(axis=1))[0] #What rows are identical\n",
    "            if matche.tolist() not in matchesA:# if it's a new kind of row save the place where they exist\n",
    "                matchesA.append(matche.tolist())\n",
    "                matchesB.append(np.where(connection_matrix[i,:]==1)[0].tolist())\n",
    "    return matchesA,matchesB \n",
    "def filter_connection_matrix(connection_matrix,left_points,right_points):\n",
    "    new_connection_matrix=connection_matrix.copy()\n",
    "    progress=1\n",
    "    old_cost=np.sum(connection_matrix)\n",
    "    correspondings=[]\n",
    "    while progress>0:\n",
    "        m,n=connection_matrix.shape\n",
    "        for i in range(m):\n",
    "            if np.sum(connection_matrix[i,:],axis=0)==1: #left marker i is connected to just one right marker j\n",
    "                j=np.where(connection_matrix[i,:]==1)\n",
    "                connection_matrix[:,j]=0\n",
    "                new_connection_matrix[:,j]=0\n",
    "                connection_matrix[i,j]=1\n",
    "                if (i,j[0][0]) not in correspondings:\n",
    "                    correspondings.append([i,j[0][0]])\n",
    "        for i in range(n):\n",
    "            if np.sum(connection_matrix[:,i],axis=0)==1: #left marker i in the right is connected to just one the left \n",
    "                j=np.where(connection_matrix[:,i]==1)\n",
    "                connection_matrix[j,:]=0\n",
    "                new_connection_matrix[j,:]=0\n",
    "                connection_matrix[j,i]=1\n",
    "                if [j[0][0],i] not in correspondings:\n",
    "                    correspondings.append([j[0][0],i])\n",
    "        progress=old_cost-np.sum(connection_matrix)\n",
    "        old_cost=np.sum(connection_matrix)\n",
    "        correspondings=np.array(correspondings)\n",
    "        if correspondings.size != 0:\n",
    "               return new_connection_matrix,left_points[correspondings[:,0],:],right_points[correspondings[:,1],:]\n",
    "        else:\n",
    "               return new_connection_matrix,np.array([]),np.array([])\n",
    "def get_correspondings(left_points,right_points):\n",
    "    connection_matrix=calculate_connection_mateix(left_points,right_points)\n",
    "    new_cm,immediate_correspondings_left,immediate_correspondings_right=filter_connection_matrix(connection_matrix,left_points,right_points)\n",
    "    matchesLeft,matchesRight=process_filtered_connection_matrix(new_cm)\n",
    "    left_corr_sec,right_corr_sec=get_secondary_correspondings(matchesLeft,matchesRight,left_points,right_points)\n",
    "    if immediate_correspondings_left.size !=0 and left_corr_sec.size!=0:\n",
    "        return np.vstack([left_corr_sec,immediate_correspondings_left]),np.vstack([right_corr_sec,immediate_correspondings_right])\n",
    "    elif immediate_correspondings_left.size ==0 and left_corr_sec.size!=0:\n",
    "        return np.vstack([left_corr_sec]),np.vstack([right_corr_sec])\n",
    "    else:\n",
    "        return np.vstack([immediate_correspondings_left]),np.vstack([immediate_correspondings_right])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[100, 200],\n",
       "        [110, 201],\n",
       "        [110, 104]]), array([[200, 201],\n",
       "        [220, 202],\n",
       "        [200, 101]]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the corrosponding finder algorithm using dummy data\n",
    "#left_points=np.array([[104,110],[201,110],[200,100],[100,100],[202,120],[102,120],[10,100]]).reshape(-1,2)\n",
    "#right_points=np.array([[101,200],[202,220],[102,220],[103,210],[201,200],[203,210],[12,120]]).reshape(-1,2)\n",
    "left_points=np.array([[104,110],[201,110],[200,100]]).reshape(-1,2)\n",
    "right_points=np.array([[101,200],[202,220],[102,220],[103,210],[201,200],[203,210],[12,120]]).reshape(-1,2)\n",
    "left_points[:,[0,1]]=left_points[:,[1,0]]\n",
    "right_points[:,[0,1]]=right_points[:,[1,0]]\n",
    "cm=np.array([[1,0,1,1,0,0],[0,1,0,0,1,1],[1,0,1,1,0,0],[0,1,0,0,1,1],[0,1,0,0,1,1],[1,0,1,1,0,0]])\n",
    "\n",
    "connection_matrix=calculate_connection_mateix(left_points,right_points)\n",
    "new_cm,immediate_correspondings_left,immediate_correspondings_right=filter_connection_matrix(connection_matrix,left_points,right_points)\n",
    "matchesLeft,matchesRight=process_filtered_connection_matrix(new_cm)\n",
    "#L,R=get_secondary_correspondings(matchesLeft,matchesRight,left_points,right_points)\n",
    "left_corr,right_corr=get_correspondings(left_points,right_points)\n",
    "\n",
    "#A is the Matrix with less points\n",
    "left_corr,right_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-8500090f42f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#get the corrosponding points for the exteracted points from the camera frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlpts_ud\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrpts_ud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_correspondings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_ud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_ud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriangulatePoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftUndist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrightUndist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlpts_ud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrpts_ud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpoints_3d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-199-8b0a21dffceb>\u001b[0m in \u001b[0;36mget_correspondings\u001b[0;34m(left_points, right_points)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mnew_cm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimmediate_correspondings_left\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimmediate_correspondings_right\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_connection_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mmatchesLeft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatchesRight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_filtered_connection_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_cm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mleft_corr_sec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_corr_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_secondary_correspondings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatchesLeft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatchesRight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimmediate_correspondings_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft_corr_sec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimmediate_correspondings_left\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_corr_sec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimmediate_correspondings_right\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-199-8b0a21dffceb>\u001b[0m in \u001b[0;36mget_secondary_correspondings\u001b[0;34m(matchesA, matchesB, points_left, points_right)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mdists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchosens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mchosens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchosens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/py_virtualenvs/tf13/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmin\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \"\"\"\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/py_virtualenvs/tf13/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/py_virtualenvs/tf13/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36margmin\u001b[0;34m(self, axis, fill_value, out)\u001b[0m\n\u001b[1;32m   5447\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimum_fill_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5448\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5449\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "#get the corrosponding points for the exteracted points from the camera frames\n",
    "lpts_ud,rpts_ud=get_correspondings(left_ud.reshape(-1,3)[:,0:2],right_ud.reshape(-1,3)[:,0:2])\n",
    "res=cv2.triangulatePoints(leftUndist.P,rightUndist.P,lpts_ud.reshape(-1,1,2).astype(np.float32),rpts_ud.reshape(-1,1,2).astype(np.float32))\n",
    "points_3d=(res/res[-1,:])[0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((cm==cm[0,:]).all(axis=1))[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[[1,2,3],[4,5,6]]\n",
    "b=[1,2,3]\n",
    "b in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les's test the Multi marker 3D point Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing the algorithm with a stream of images\n",
    "markerExteractor_inst=markerExteractor()\n",
    "cap_right=cv2.VideoCapture('/home/rouholla/Stereo_6DOF_Tracker/output_right.avi')\n",
    "cap_left=cv2.VideoCapture('/home/rouholla/Stereo_6DOF_Tracker/output_left.avi')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output_debug.avi', fourcc, 30.0, (int(cap_left.get(3)),int(cap_left.get(4))))\n",
    "markerExteractor_inst.max_clusters = 8\n",
    "markerExteractor_inst.threshold = 200\n",
    "markerExteractor_inst.blubParams = cv2.SimpleBlobDetector_Params()\n",
    "markerExteractor_inst.blubParams.minThreshold = 50;\n",
    "markerExteractor_inst.blubParams.maxThreshold = 255;\n",
    "markerExteractor_inst.blubParams.filterByArea = True\n",
    "markerExteractor_inst.blubParams.minArea = 0\n",
    "markerExteractor_inst.blubParams.filterByCircularity = True\n",
    "markerExteractor_inst.blubParams.minCircularity = 0.3\n",
    "markerExteractor_inst.blubParams.filterByConvexity = True\n",
    "markerExteractor_inst.blubParams.minConvexity = 0.9\n",
    "markerExteractor_inst.blubParams.filterByInertia = True\n",
    "markerExteractor_inst.blubParams.minInertiaRatio = 0.1\n",
    "markerExteractor_inst.blubParams.blobColor = 255\n",
    "while cap_left.isOpened():\n",
    "    ret,img_left=cap_left.read()\n",
    "    ret,img_right=cap_right.read()\n",
    "    if ret==True:\n",
    "        points_left=markerExteractor_inst.detect(img_left)\n",
    "        points_right=markerExteractor_inst.detect(img_right)\n",
    "        if (points_left is not None) and (points_right is not None):\n",
    "            left_ud=leftUndist.process(points_left)\n",
    "            right_ud=rightUndist.process(points_right)\n",
    "            for i in range(min(len(points_left),len(points_right))):\n",
    "                cv2.circle(img_left,(int(round(points_left[i,0])), int(round(points_left[i,1]))), 2, (255,0,255), -1)\n",
    "                cv2.circle(img_right,(int(round(points_right[i,0])), int(round(points_right[i,1]))), 2, (255,0,255), -1)\n",
    "        lpts_ud,rpts_ud=get_correspondings(left_ud.reshape(-1,3)[:,0:2],right_ud.reshape(-1,3)[:,0:2])\n",
    "        \n",
    "        #print((lpts_ud.shape[0],rpts_ud.shape[0]))\n",
    "        res=cv2.triangulatePoints(leftUndist.P,rightUndist.P,lpts_ud.reshape(-1,1,2).astype(np.float32),rpts_ud.reshape(-1,1,2).astype(np.float32))\n",
    "        points_3d=res[0:3,:]/res[-1,:]\n",
    "        #print(points_3d[-1,-1])\n",
    "        if points_3d[-1,-1] >1000:\n",
    "            cv2.imwrite('/home/rouholla/faulty_right_image.jpg',img_right)\n",
    "            cv2.imwrite('/home/rouholla/faulty_left_image.jpg',img_left)\n",
    "            print(points_left)\n",
    "            print(points_right)\n",
    "            \n",
    "            break\n",
    "\n",
    "        cv2.imshow('Frame',np.hstack([img_left,img_right]))\n",
    "        out.write(img_left)\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            cv2.imwrite('faulty_image.jpg',img_right)\n",
    "            break\n",
    "    else:\n",
    "        break #Break the while loop if no frames could be captured\n",
    "cv2.destroyAllWindows()     \n",
    "out.release()\n",
    "cap_left.release()\n",
    "cap_right.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1842181  0.2366365  0.19035164 0.10936636]\n",
      " [0.00180847 0.00303939 0.07572664 0.01582983]\n",
      " [0.72752655 0.7797519  0.7661044  0.77551484]]\n"
     ]
    }
   ],
   "source": [
    "print(points_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.abs(left_points[i,1]-right_points[j,1]) for i,j in range(3,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(left_points[0,1]-right_points[0,1])<10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
